{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE-6242 - Team 157 - Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__  \n",
    "1. Remove other stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global assumption panel\n",
    "\n",
    "## general\n",
    "TRAIN_MODELS = False # if true, we add a lot of time\n",
    "\n",
    "## data gathering\n",
    "READ_CLEANED_OR_RAW = 'Clean' # ['Clean', 'Raw']\n",
    "N_DATA_ROWS_PER_GENRE = 1500 # Use -1 to retrieve all rows\n",
    "\n",
    "## embedding\n",
    "EMBED_STRATEGY = 'DistilBERT' # ['DistilBERT', 'GloVe']\n",
    "\n",
    "## modeling - preprocessing\n",
    "VAL_PCT = 0.15 # the percent of data we want to withhold for testing\n",
    "BATCH_SIZE = 32 # bigger means faster training, but more memory use\n",
    "\n",
    "## modeling - architecture\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "NUM_HEADS = 8\n",
    "assert HIDDEN_SIZE % NUM_HEADS == 0\n",
    "\n",
    "## modeling - training\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "\n",
    "## general use\n",
    "from datetime import datetime\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "\n",
    "## project code\n",
    "from project_code import data_gathering, genre_classification\n",
    "from embedding import distilbert, glove\n",
    "from modeling import preprocessing, training\n",
    "from architectures import distilbert_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Start Time = 2025-03-26 14:42:16\n",
      "Device = cpu\n"
     ]
    }
   ],
   "source": [
    "# more global assumptions\n",
    "START_TIME = datetime.now()\n",
    "print(f'Script Start Time = {START_TIME.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device = {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "if TRAIN_MODELS:\n",
    "    if READ_CLEANED_OR_RAW == 'Raw': \n",
    "        lyrics = data_gathering.read_and_clean_raw_lyrics(\n",
    "            n_rows = 'All',\n",
    "            exclude_non_english = True,\n",
    "            resample_genres = True,\n",
    "            save_data = True\n",
    "        )\n",
    "    elif READ_CLEANED_OR_RAW == 'Clean':\n",
    "        lyrics, genre_map = data_gathering.read_cleaned_lyrics(\n",
    "            n_rows_per_genre = N_DATA_ROWS_PER_GENRE\n",
    "        )\n",
    "else:\n",
    "    genre_map = {0: 'country', 1: 'misc', 2: 'pop', 3: 'rap', 4: 'rb', 5: 'rock'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings using word2vec\n",
    "if TRAIN_MODELS:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        lyrics_embed = glove.create_glove_matrix(data = lyrics, target_col = 'cleaned_lyrics')\n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        # lyrics_embed = distilbert.distilbert_embed_all_docs(data = lyrics, target_col = 'lyrics')\n",
    "        lyrics_embed = distilbert.embed_all_lyrics_v2(\n",
    "            data = lyrics,\n",
    "            target_col = 'lyrics',\n",
    "            batch_size = BATCH_SIZE * 2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders (train, val) and data sets (test)\n",
    "if TRAIN_MODELS:\n",
    "    lyrics_train, lyrics_val, lyrics_test = preprocessing.create_datasets(\n",
    "        data_embed = lyrics_embed,\n",
    "        labels = lyrics['genre'],\n",
    "        label_mapping = genre_map,\n",
    "        val_pct = VAL_PCT,\n",
    "        batch_size = BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertRNN(\n",
       "  (rnn): GRU(768, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the baseline RNN Model\n",
    "if TRAIN_MODELS:\n",
    "    n_songs, embed_dim = lyrics_embed.shape\n",
    "else:\n",
    "    embed_dim = 768\n",
    "\n",
    "base_model = distilbert_clf.DistilBertRNN(\n",
    "    input_dim = embed_dim,\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    output_dim = len(genre_map),\n",
    "    type = 'GRU',\n",
    "    num_layers = NUM_LAYERS,\n",
    "    dropout = DROPOUT\n",
    ").to(DEVICE)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance - pre training\n",
    "if TRAIN_MODELS:\n",
    "    pre_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = base_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "if TRAIN_MODELS:\n",
    "    training.nn_training(\n",
    "        model = base_model,\n",
    "        train_loader = lyrics_train,\n",
    "        val_loader = lyrics_val,\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        patience = PATIENCE,\n",
    "        verbose = True,\n",
    "        print_every = 1\n",
    "    )\n",
    "else:\n",
    "    state_dict = torch.load('models/MGC_DistilBertRNN.pth', map_location = torch.device(DEVICE))\n",
    "    base_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance - post traing\n",
    "if TRAIN_MODELS:\n",
    "    post_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = base_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )\n",
    "\n",
    "    print(f'Training Improvement On Accuracy = +{(post_train_acc - pre_train_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Homemade Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertDeepTransformer(\n",
       "  (attention_layers): ModuleList(\n",
       "    (0-1): 2 x MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ffn_layers): ModuleList(\n",
       "    (0-1): 2 x Sequential(\n",
       "      (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_layers_attn): ModuleList(\n",
       "    (0-1): 2 x LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (norm_layers_ffn): ModuleList(\n",
       "    (0-1): 2 x LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the transformer model\n",
    "if TRAIN_MODELS:\n",
    "    n_songs, embed_dim = lyrics_embed.shape\n",
    "else:\n",
    "    embed_dim = 768\n",
    "    \n",
    "transformer_model = distilbert_clf.DistilBertDeepTransformer(\n",
    "    input_dim = embed_dim,\n",
    "    num_heads = NUM_HEADS,\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    output_dim = len(genre_map),\n",
    "    num_layers = NUM_LAYERS,\n",
    "    dropout = DROPOUT\n",
    ").to(DEVICE)\n",
    "transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance - pre training\n",
    "if TRAIN_MODELS:\n",
    "    pre_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = transformer_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "if TRAIN_MODELS:\n",
    "    training.nn_training(\n",
    "        model = transformer_model,\n",
    "        train_loader = lyrics_train,\n",
    "        val_loader = lyrics_val,\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        patience = PATIENCE,\n",
    "        verbose = True,\n",
    "        print_every = 1\n",
    "    )\n",
    "else:\n",
    "    state_dict = torch.load('models/MGC_DistilBertDeepTransformer.pth', map_location = torch.device(DEVICE))\n",
    "    transformer_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance - post traing\n",
    "if TRAIN_MODELS:\n",
    "    post_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = transformer_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )\n",
    "\n",
    "    print(f'Training Improvement On Accuracy = +{(post_train_acc - pre_train_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Lyric Genre Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test lyrics\n",
    "pop_test = \"\"\"\"\n",
    "One. Don't pick up the phone. You know he's only calling cause he's drunk and alone.\n",
    "Two. Don't let him in. You'll have to kick him out again.\n",
    "Three. Don't be a friend. Cause you know you'll only wake up in his bed in the morning.\n",
    "Cause if you're under him. You're not getting over him.\n",
    "\"\"\"\n",
    "\n",
    "rock_test = \"\"\"\n",
    "We come from the land of the ice and snow\n",
    "From the midnight sun where the hot springs blow\n",
    "The hammer of the gods will drive our ships to new lands\n",
    "To fight the horde, singing and crying: Valhalla, I am coming!\n",
    "On we sweep with threshing oar\n",
    "Our only goal will be the western shore\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics:\n",
      "\n",
      "We come from the land of the ice and snow\n",
      "From the midnight sun where the hot springs blow\n",
      "The hammer of the gods will drive our ships to new lands\n",
      "To fight the horde, singing and crying: Valhalla, I am coming!\n",
      "On we sweep with threshing oar\n",
      "Our only goal will be the western shore\n",
      "\n",
      "\n",
      "Predicted Genre: rock (idx = 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rock'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction for a custom song\n",
    "genre_classification.distilerbert_clf_prediction(\n",
    "    lyrics = rock_test,\n",
    "    clf_model = transformer_model, # base_model, transformer_model\n",
    "    label_mapping = genre_map,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script End Time = 2025-03-26 14:42:17\n",
      "Duration = 0.00min\n"
     ]
    }
   ],
   "source": [
    "# wrap up\n",
    "END_TIME = datetime.now()\n",
    "SCRIPT_TIME = (END_TIME - START_TIME).seconds\n",
    "print(f'Script End Time = {END_TIME.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Duration = {SCRIPT_TIME / 60:.2f}min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6242-team157-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
