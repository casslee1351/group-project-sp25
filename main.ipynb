{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE-6242 - Team 157 - Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__  \n",
    "1. Remove other stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global assumption panel\n",
    "\n",
    "## general\n",
    "TRAIN_MODELS = True # if true, we add a lot of time\n",
    "\n",
    "## data gathering\n",
    "READ_CLEANED_OR_RAW = 'Clean' # ['Clean', 'Raw']\n",
    "N_DATA_ROWS_PER_GENRE = 50 # ['All', int]\n",
    "\n",
    "## embedding\n",
    "EMBED_STRATEGY = 'GloVe' # ['DistilBERT', 'GloVe']\n",
    "MAX_GLOVE_LENGTH = 200 # [None, int]\n",
    "\n",
    "## modeling - preprocessing\n",
    "VAL_PCT = 0.15 # the percent of data we want to withhold for testing\n",
    "BATCH_SIZE = 32 # bigger means faster training, but more memory use\n",
    "\n",
    "## modeling - architecture\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "NUM_HEADS = 8 if EMBED_STRATEGY == 'DistilBERT' else 6\n",
    "if EMBED_STRATEGY == 'GloVe':\n",
    "    assert 300 % NUM_HEADS == 0\n",
    "elif EMBED_STRATEGY == 'DistilBERT':\n",
    "    assert 768 % NUM_HEADS == 0\n",
    "\n",
    "## modeling - training\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "\n",
    "## general use\n",
    "from datetime import datetime\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "\n",
    "## project code\n",
    "from project_code import data_gathering, genre_classification\n",
    "from embedding import distilbert, glove\n",
    "from modeling import preprocessing, training\n",
    "from architectures import nn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Start Time = 2025-03-30 13:34:00\n",
      "Device = cpu\n"
     ]
    }
   ],
   "source": [
    "# more global assumptions\n",
    "START_TIME = datetime.now()\n",
    "print(f'Script Start Time = {START_TIME.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device = {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre Counts Before Resampling:\n",
      "\tpop: 394195\n",
      "\trap: 394195\n",
      "\trock: 394195\n",
      "\trb: 155082\n",
      "\tmisc: 140986\n",
      "\tcountry: 86658\n",
      "\n",
      "Genre Counts After Resampling:\n",
      "\tcountry: 50\n",
      "\tmisc: 50\n",
      "\tpop: 50\n",
      "\trap: 50\n",
      "\trb: 50\n",
      "\trock: 50\n",
      "\n",
      "Cleaned Lyrics: Shape = (300, 2)\n",
      "\tColumns = ['lyrics', 'genre']\n",
      "Genre Mapping = {0: 'country', 1: 'misc', 2: 'pop', 3: 'rap', 4: 'rb', 5: 'rock'}\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "if TRAIN_MODELS:\n",
    "    if READ_CLEANED_OR_RAW == 'Raw': \n",
    "        lyrics = data_gathering.read_and_clean_raw_lyrics(\n",
    "            n_rows = 'All',\n",
    "            exclude_non_english = True,\n",
    "            resample_genres = True,\n",
    "            save_data = True\n",
    "        )\n",
    "    elif READ_CLEANED_OR_RAW == 'Clean':\n",
    "        lyrics, genre_map = data_gathering.read_cleaned_lyrics(\n",
    "            n_rows_per_genre = N_DATA_ROWS_PER_GENRE\n",
    "        )\n",
    "else:\n",
    "    genre_map = {0: 'country', 1: 'misc', 2: 'pop', 3: 'rap', 4: 'rb', 5: 'rock'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed + Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting GloVe Embedding Index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917494it [01:44, 18281.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting Word Indices to GloVe Vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 4721.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GloVe Embedded Lyrics: Shape = (n_songs, max_seq_len, embed_len) = torch.Size([300, 200, 300])\n",
      "\tPadded Sequences: Shape = (n_songs, max_seq_len) = (300, 200)\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings using word2vec\n",
    "if TRAIN_MODELS:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        lyrics_embed, glove_index = glove.embed_all_lyrics(\n",
    "            data = lyrics,\n",
    "            target_col = 'lyrics',\n",
    "            custom_max_seq_len = MAX_GLOVE_LENGTH\n",
    "        )\n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        # lyrics_embed = distilbert.distilbert_embed_all_docs(data = lyrics, target_col = 'lyrics')\n",
    "        lyrics_embed = distilbert.embed_all_lyrics_v2(\n",
    "            data = lyrics,\n",
    "            target_col = 'lyrics',\n",
    "            batch_size = BATCH_SIZE * 2\n",
    "        )\n",
    "else:\n",
    "    if EMBED_STRATEGY == \"GloVe\":\n",
    "        glove_index = glove.read_glove_embedding_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7 Batches of Size 32 For Training\n",
      "Val: 2 Batches of Size 32 For Training\n",
      "Test: 2 Batches of Size 32 For Final Eval\n"
     ]
    }
   ],
   "source": [
    "# create data loaders (train, val) and data sets (test)\n",
    "if TRAIN_MODELS:\n",
    "    lyrics_train, lyrics_val, lyrics_test = preprocessing.create_datasets(\n",
    "        data_embed = lyrics_embed,\n",
    "        labels = lyrics['genre'],\n",
    "        label_mapping = genre_map,\n",
    "        val_pct = VAL_PCT,\n",
    "        batch_size = BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseRNN(\n",
       "  (rnn): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the baseline RNN Model\n",
    "if TRAIN_MODELS:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        n_songs, max_seq_len, embed_dim = lyrics_embed.shape \n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        n_songs, embed_dim = lyrics_embed.shape\n",
    "else:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        embed_dim = 300 \n",
    "    elif EMBED_STRATEGY == 'DistilBert':\n",
    "        embed_dim = 768\n",
    "\n",
    "base_model = nn_clf.BaseRNN(\n",
    "    input_dim = embed_dim,\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    output_dim = len(genre_map),\n",
    "    type = 'GRU',\n",
    "    num_layers = NUM_LAYERS,\n",
    "    dropout = DROPOUT\n",
    ").to(DEVICE)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 15.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - pre training\n",
    "if TRAIN_MODELS:\n",
    "    pre_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = base_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:24<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 50] Train Loss = 1.7454, Val Loss = 1.6562 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:10<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 / 50] Train Loss = 1.5020, Val Loss = 1.5655 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 / 50] Train Loss = 1.3038, Val Loss = 1.3934 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 / 50] Train Loss = 1.0683, Val Loss = 1.4891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 / 50] Train Loss = 0.8645, Val Loss = 1.6548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 / 50] Train Loss = 0.5422, Val Loss = 1.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 / 50] Train Loss = 0.4140, Val Loss = 1.9113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 / 50] Train Loss = 0.2069, Val Loss = 2.0655\n",
      "Early Stopping Triggered. Training Stopped.\n",
      "\tBest Epoch = 2, Best Val Loss = 1.3933932185173035\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "if TRAIN_MODELS:\n",
    "    training.nn_training(\n",
    "        model = base_model,\n",
    "        train_loader = lyrics_train,\n",
    "        val_loader = lyrics_val,\n",
    "        embed_strategy = EMBED_STRATEGY,\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        patience = PATIENCE,\n",
    "        verbose = True,\n",
    "        print_every = 1\n",
    "    )\n",
    "else:\n",
    "    state_dict = torch.load(f'models/{EMBED_STRATEGY}_BaseRNN_Trained.pth', map_location = torch.device(DEVICE))\n",
    "    base_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 31.11%\n",
      "Training Improvement On Accuracy = +15.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - post traing\n",
    "if TRAIN_MODELS:\n",
    "    post_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = base_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )\n",
    "\n",
    "    print(f'Training Improvement On Accuracy = +{(post_train_acc - pre_train_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Homemade Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepTransformer(\n",
       "  (attention_layers): ModuleList(\n",
       "    (0-1): 2 x MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ffn_layers): ModuleList(\n",
       "    (0-1): 2 x Sequential(\n",
       "      (0): Linear(in_features=300, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=300, bias=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_layers_attn): ModuleList(\n",
       "    (0-1): 2 x LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (norm_layers_ffn): ModuleList(\n",
       "    (0-1): 2 x LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the transformer model\n",
    "if TRAIN_MODELS:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        n_songs, max_seq_len, embed_dim = lyrics_embed.shape \n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        n_songs, embed_dim = lyrics_embed.shape\n",
    "else:\n",
    "    if EMBED_STRATEGY == 'Glove':\n",
    "        embed_dim = 300 \n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        embed_dim = 768\n",
    "    \n",
    "transformer_model = nn_clf.DeepTransformer(\n",
    "    input_dim = embed_dim,\n",
    "    num_heads = NUM_HEADS,\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    output_dim = len(genre_map),\n",
    "    num_layers = NUM_LAYERS,\n",
    "    dropout = DROPOUT\n",
    ").to(DEVICE)\n",
    "transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 20.00%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - pre training\n",
    "if TRAIN_MODELS:\n",
    "    pre_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = transformer_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 50] Train Loss = 1.9669, Val Loss = 1.4951 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 / 50] Train Loss = 1.5351, Val Loss = 1.7814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 / 50] Train Loss = 1.3538, Val Loss = 1.2743 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 / 50] Train Loss = 1.1881, Val Loss = 1.2858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 / 50] Train Loss = 0.9709, Val Loss = 1.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 / 50] Train Loss = 0.7353, Val Loss = 1.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 / 50] Train Loss = 0.5024, Val Loss = 1.7593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 / 50] Train Loss = 0.3571, Val Loss = 1.7655\n",
      "Early Stopping Triggered. Training Stopped.\n",
      "\tBest Epoch = 2, Best Val Loss = 1.27433842420578\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "if TRAIN_MODELS:\n",
    "    training.nn_training(\n",
    "        model = transformer_model,\n",
    "        train_loader = lyrics_train,\n",
    "        val_loader = lyrics_val,\n",
    "        embed_strategy = EMBED_STRATEGY,\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        patience = PATIENCE,\n",
    "        verbose = True,\n",
    "        print_every = 1\n",
    "    )\n",
    "else:\n",
    "    state_dict = torch.load(f'models/{EMBED_STRATEGY}_DeepTransformer_Trained.pth', map_location = torch.device(DEVICE))\n",
    "    transformer_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 40.00%\n",
      "Training Improvement On Accuracy = +20.00%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - post traing\n",
    "if TRAIN_MODELS:\n",
    "    post_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = transformer_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )\n",
    "\n",
    "    print(f'Training Improvement On Accuracy = +{(post_train_acc - pre_train_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:01<00:00, 236.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Length = 210\n",
      "Val:   Length = 45\n",
      "Test:  Length = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create GPT2 Fine Tuning Datasets\n",
    "lyrics_gpt_train, lyrics_gpt_val, lyrics_gpt_test, gpt_tokenizer = preprocessing.gpt2_create_datasets(\n",
    "    data = lyrics, \n",
    "    label_mapping = genre_map,\n",
    "    input_col = 'lyrics', label_col = 'genre',\n",
    "    val_pct = VAL_PCT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=6, bias=False)\n",
      ")\n",
      "GPT2 Fine Tuning: Start Time = 2025-03-30 13:34:53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 41/159 08:04 < 24:26, 0.08 it/s, Epoch 0.75/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     94\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mgpt2_fine_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlyrics_gpt_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlyrics_gpt_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlyrics_gpt_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_tokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenre_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# BATCH_SIZE,\u001b[39;49;00m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# NUM_EPOCHS,\u001b[39;49;00m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mgpt2_fine_tuning\u001b[39m\u001b[34m(train_dataset, val_dataset, test_dataset, input_tokenizer, num_labels, batch_size, num_epochs, learning_rate, save_model, verbose)\u001b[39m\n\u001b[32m     73\u001b[39m     train_start = datetime.now()\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mGPT2 Fine Tuning: Start Time = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_start.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     79\u001b[39m     train_end = datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\transformers\\trainer.py:2556\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2549\u001b[39m context = (\n\u001b[32m   2550\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2551\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2553\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2554\u001b[39m )\n\u001b[32m   2555\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2556\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2559\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2561\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2562\u001b[39m ):\n\u001b[32m   2563\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2564\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\transformers\\trainer.py:3764\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3762\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3764\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\accelerate\\accelerator.py:1964\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28mself\u001b[39m.scaler.scale(loss).backward(**kwargs)\n\u001b[32m   1963\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# fine tune the GPT2 model\n",
    "gpt2_model_fine_tuned = training.gpt2_fine_tuning(\n",
    "    train_dataset = lyrics_gpt_train,\n",
    "    val_dataset = lyrics_gpt_val,\n",
    "    test_dataset = lyrics_gpt_test,\n",
    "    input_tokenizer = gpt_tokenizer,\n",
    "    num_labels = len(genre_map),\n",
    "    batch_size = 4, # BATCH_SIZE,\n",
    "    num_epochs = 3, # NUM_EPOCHS,\n",
    "    learning_rate = LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Lyric Genre Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test lyrics\n",
    "pop_test = \"\"\"\"\n",
    "One. Don't pick up the phone. You know he's only calling cause he's drunk and alone.\n",
    "Two. Don't let him in. You'll have to kick him out again.\n",
    "Three. Don't be a friend. Cause you know you'll only wake up in his bed in the morning.\n",
    "Cause if you're under him. You're not getting over him.\n",
    "\"\"\"\n",
    "\n",
    "rock_test = \"\"\"\n",
    "We come from the land of the ice and snow\n",
    "From the midnight sun where the hot springs blow\n",
    "The hammer of the gods will drive our ships to new lands\n",
    "To fight the horde, singing and crying: Valhalla, I am coming!\n",
    "On we sweep with threshing oar\n",
    "Our only goal will be the western shore\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics:\n",
      "\n",
      "We come from the land of the ice and snow\n",
      "From the midnight sun where the hot springs blow\n",
      "The hammer of the gods will drive our ships to new lands\n",
      "To fight the horde, singing and crying: Valhalla, I am coming!\n",
      "On we sweep with threshing oar\n",
      "Our only goal will be the western shore\n",
      "\n",
      "\n",
      "Predicted Genre: rock (idx = 5)\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a custom song\n",
    "if EMBED_STRATEGY == 'DistilBERT':\n",
    "    genre_classification.distilerbert_clf_prediction(\n",
    "        lyrics = rock_test,\n",
    "        clf_model = transformer_model, # base_model, transformer_model\n",
    "        label_mapping = genre_map,\n",
    "        device = DEVICE\n",
    "    )\n",
    "elif EMBED_STRATEGY == 'GloVe':\n",
    "    genre_classification.glove_clf_prediction(\n",
    "        lyrics = rock_test, # pop_test, rock_test\n",
    "        clf_model = transformer_model,\n",
    "        glove_index = glove_index,\n",
    "        label_mapping = genre_map,\n",
    "        max_seq_len = MAX_GLOVE_LENGTH,\n",
    "        device = DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script End Time = 2025-03-27 14:27:01\n",
      "Duration = 34.17min\n"
     ]
    }
   ],
   "source": [
    "# wrap up\n",
    "END_TIME = datetime.now()\n",
    "SCRIPT_TIME = (END_TIME - START_TIME).seconds\n",
    "print(f'Script End Time = {END_TIME.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Duration = {SCRIPT_TIME / 60:.2f}min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6242-team157-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
