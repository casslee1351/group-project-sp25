{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE-6242 - Team 157 - Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__  \n",
    "1. Remove other stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global assumption panel\n",
    "\n",
    "## general\n",
    "TRAIN_MODELS = True # if true, we add a lot of time\n",
    "\n",
    "## data gathering\n",
    "READ_CLEANED_OR_RAW = 'Clean' # ['Clean', 'Raw']\n",
    "N_DATA_ROWS_PER_GENRE = 1000 # ['All', int]\n",
    "\n",
    "## embedding\n",
    "EMBED_STRATEGY = 'DistilBERT' # ['DistilBERT', 'GloVe']\n",
    "MAX_GLOVE_LENGTH = 200 # [None, int]\n",
    "\n",
    "## modeling - preprocessing\n",
    "VAL_PCT = 0.15 # the percent of data we want to withhold for testing\n",
    "BATCH_SIZE = 32 # bigger means faster training, but more memory use\n",
    "\n",
    "## modeling - architecture\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "NUM_HEADS = 8 if EMBED_STRATEGY == 'DistilBERT' else 6\n",
    "if EMBED_STRATEGY == 'GloVe':\n",
    "    assert 300 % NUM_HEADS == 0\n",
    "elif EMBED_STRATEGY == 'DistilBERT':\n",
    "    assert 768 % NUM_HEADS == 0\n",
    "\n",
    "## modeling - training\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nccru\\anaconda3\\envs\\cse6242-team157-project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "\n",
    "## general use\n",
    "from datetime import datetime\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "\n",
    "## project code\n",
    "from project_code import data_gathering, genre_classification\n",
    "from embedding import distilbert, glove\n",
    "from modeling import preprocessing, training\n",
    "from architectures import nn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Start Time = 2025-03-27 13:52:50\n",
      "Device = cpu\n"
     ]
    }
   ],
   "source": [
    "# more global assumptions\n",
    "START_TIME = datetime.now()\n",
    "print(f'Script Start Time = {START_TIME.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device = {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre Counts Before Resampling:\n",
      "\tpop: 394195\n",
      "\trap: 394195\n",
      "\trock: 394195\n",
      "\trb: 155082\n",
      "\tmisc: 140986\n",
      "\tcountry: 86658\n",
      "\n",
      "Genre Counts After Resampling:\n",
      "\tcountry: 1000\n",
      "\tmisc: 1000\n",
      "\tpop: 1000\n",
      "\trap: 1000\n",
      "\trb: 1000\n",
      "\trock: 1000\n",
      "\n",
      "Cleaned Lyrics: Shape = (6000, 2)\n",
      "\tColumns = ['lyrics', 'genre']\n",
      "Genre Mapping = {0: 'country', 1: 'misc', 2: 'pop', 3: 'rap', 4: 'rb', 5: 'rock'}\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "if TRAIN_MODELS:\n",
    "    if READ_CLEANED_OR_RAW == 'Raw': \n",
    "        lyrics = data_gathering.read_and_clean_raw_lyrics(\n",
    "            n_rows = 'All',\n",
    "            exclude_non_english = True,\n",
    "            resample_genres = True,\n",
    "            save_data = True\n",
    "        )\n",
    "    elif READ_CLEANED_OR_RAW == 'Clean':\n",
    "        lyrics, genre_map = data_gathering.read_cleaned_lyrics(\n",
    "            n_rows_per_genre = N_DATA_ROWS_PER_GENRE\n",
    "        )\n",
    "else:\n",
    "    genre_map = {0: 'country', 1: 'misc', 2: 'pop', 3: 'rap', 4: 'rb', 5: 'rock'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [31:38<00:00, 20.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT Embedded Lyrics: Shape = (n_songs, distilbert_embed_len) = torch.Size([6000, 768])\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings using word2vec\n",
    "if TRAIN_MODELS:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        lyrics_embed, glove_index = glove.embed_all_lyrics(\n",
    "            data = lyrics,\n",
    "            target_col = 'lyrics',\n",
    "            custom_max_seq_len = MAX_GLOVE_LENGTH\n",
    "        )\n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        # lyrics_embed = distilbert.distilbert_embed_all_docs(data = lyrics, target_col = 'lyrics')\n",
    "        lyrics_embed = distilbert.embed_all_lyrics_v2(\n",
    "            data = lyrics,\n",
    "            target_col = 'lyrics',\n",
    "            batch_size = BATCH_SIZE * 2\n",
    "        )\n",
    "else:\n",
    "    if EMBED_STRATEGY == \"GloVe\":\n",
    "        glove_index = glove.read_glove_embedding_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 132 Batches of Size 32 For Training\n",
      "Val: 29 Batches of Size 32 For Training\n",
      "Test: 29 Batches of Size 32 For Final Eval\n"
     ]
    }
   ],
   "source": [
    "# create data loaders (train, val) and data sets (test)\n",
    "if TRAIN_MODELS:\n",
    "    lyrics_train, lyrics_val, lyrics_test = preprocessing.create_datasets(\n",
    "        data_embed = lyrics_embed,\n",
    "        labels = lyrics['genre'],\n",
    "        label_mapping = genre_map,\n",
    "        val_pct = VAL_PCT,\n",
    "        batch_size = BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseRNN(\n",
       "  (rnn): GRU(768, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the baseline RNN Model\n",
    "if TRAIN_MODELS:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        n_songs, max_seq_len, embed_dim = lyrics_embed.shape \n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        n_songs, embed_dim = lyrics_embed.shape\n",
    "else:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        embed_dim = 300 \n",
    "    elif EMBED_STRATEGY == 'DistilBert':\n",
    "        embed_dim = 768\n",
    "\n",
    "base_model = nn_clf.BaseRNN(\n",
    "    input_dim = embed_dim,\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    output_dim = len(genre_map),\n",
    "    type = 'GRU',\n",
    "    num_layers = NUM_LAYERS,\n",
    "    dropout = DROPOUT\n",
    ").to(DEVICE)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 15.33%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - pre training\n",
    "if TRAIN_MODELS:\n",
    "    pre_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = base_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:04<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 50] Train Loss = 1.3531, Val Loss = 1.3235 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:03<00:00, 35.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 / 50] Train Loss = 1.1806, Val Loss = 1.2733 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 46.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 / 50] Train Loss = 1.1326, Val Loss = 1.1914 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 48.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 / 50] Train Loss = 1.1042, Val Loss = 1.2147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 53.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 / 50] Train Loss = 1.0878, Val Loss = 1.1832 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 55.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 / 50] Train Loss = 1.0732, Val Loss = 1.1697 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 60.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 / 50] Train Loss = 1.0567, Val Loss = 1.1119 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 58.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 / 50] Train Loss = 1.0415, Val Loss = 1.1613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 54.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 / 50] Train Loss = 1.0109, Val Loss = 1.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 49.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 / 50] Train Loss = 0.9914, Val Loss = 1.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 54.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 / 50] Train Loss = 0.9884, Val Loss = 1.1425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 / 50] Train Loss = 0.9664, Val Loss = 1.2277\n",
      "Early Stopping Triggered. Training Stopped.\n",
      "\tBest Epoch = 6, Best Val Loss = 1.1118628223394524\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "if TRAIN_MODELS:\n",
    "    training.nn_training(\n",
    "        model = base_model,\n",
    "        train_loader = lyrics_train,\n",
    "        val_loader = lyrics_val,\n",
    "        embed_strategy = EMBED_STRATEGY,\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        patience = PATIENCE,\n",
    "        verbose = True,\n",
    "        print_every = 1\n",
    "    )\n",
    "else:\n",
    "    state_dict = torch.load(f'models/{EMBED_STRATEGY}_BaseRNN_Trained.pth', map_location = torch.device(DEVICE))\n",
    "    base_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 57.89%\n",
      "Training Improvement On Accuracy = +42.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - post traing\n",
    "if TRAIN_MODELS:\n",
    "    post_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = base_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )\n",
    "\n",
    "    print(f'Training Improvement On Accuracy = +{(post_train_acc - pre_train_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Homemade Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepTransformer(\n",
       "  (attention_layers): ModuleList(\n",
       "    (0-1): 2 x MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ffn_layers): ModuleList(\n",
       "    (0-1): 2 x Sequential(\n",
       "      (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_layers_attn): ModuleList(\n",
       "    (0-1): 2 x LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (norm_layers_ffn): ModuleList(\n",
       "    (0-1): 2 x LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the transformer model\n",
    "if TRAIN_MODELS:\n",
    "    if EMBED_STRATEGY == 'GloVe':\n",
    "        n_songs, max_seq_len, embed_dim = lyrics_embed.shape \n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        n_songs, embed_dim = lyrics_embed.shape\n",
    "else:\n",
    "    if EMBED_STRATEGY == 'Glove':\n",
    "        embed_dim = 300 \n",
    "    elif EMBED_STRATEGY == 'DistilBERT':\n",
    "        embed_dim = 768\n",
    "    \n",
    "transformer_model = nn_clf.DeepTransformer(\n",
    "    input_dim = embed_dim,\n",
    "    num_heads = NUM_HEADS,\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    output_dim = len(genre_map),\n",
    "    num_layers = NUM_LAYERS,\n",
    "    dropout = DROPOUT\n",
    ").to(DEVICE)\n",
    "transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 14.22%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - pre training\n",
    "if TRAIN_MODELS:\n",
    "    pre_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = transformer_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:04<00:00, 27.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 50] Train Loss = 1.6377, Val Loss = 1.4292 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 25.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 / 50] Train Loss = 1.2864, Val Loss = 1.3281 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 26.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 / 50] Train Loss = 1.2624, Val Loss = 1.3525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 / 50] Train Loss = 1.1947, Val Loss = 1.4848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 25.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 / 50] Train Loss = 1.1973, Val Loss = 1.3189 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 26.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 / 50] Train Loss = 1.2262, Val Loss = 1.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:04<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 / 50] Train Loss = 1.1413, Val Loss = 1.2904 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:04<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 / 50] Train Loss = 1.1669, Val Loss = 1.3966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 25.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 / 50] Train Loss = 1.1247, Val Loss = 1.3619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 25.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 / 50] Train Loss = 1.1237, Val Loss = 1.3185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 23.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 / 50] Train Loss = 1.0951, Val Loss = 1.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:06<00:00, 21.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 / 50] Train Loss = 1.1034, Val Loss = 1.2904 **New Best Model**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:04<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 / 50] Train Loss = 1.0904, Val Loss = 1.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 25.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 / 50] Train Loss = 1.1054, Val Loss = 1.4793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:04<00:00, 26.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 / 50] Train Loss = 1.0618, Val Loss = 1.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:05<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 / 50] Train Loss = 1.0715, Val Loss = 1.3390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:07<00:00, 18.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 / 50] Train Loss = 1.1030, Val Loss = 1.3846\n",
      "Early Stopping Triggered. Training Stopped.\n",
      "\tBest Epoch = 11, Best Val Loss = 1.290380128498735\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "if TRAIN_MODELS:\n",
    "    training.nn_training(\n",
    "        model = transformer_model,\n",
    "        train_loader = lyrics_train,\n",
    "        val_loader = lyrics_val,\n",
    "        embed_strategy = EMBED_STRATEGY,\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        patience = PATIENCE,\n",
    "        verbose = True,\n",
    "        print_every = 1\n",
    "    )\n",
    "else:\n",
    "    state_dict = torch.load(f'models/{EMBED_STRATEGY}_DeepTransformer_Trained.pth', map_location = torch.device(DEVICE))\n",
    "    transformer_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 51.78%\n",
      "Training Improvement On Accuracy = +37.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance - post traing\n",
    "if TRAIN_MODELS:\n",
    "    post_train_acc = training.evaluate_nn_model_against_test_set(\n",
    "        model = transformer_model,\n",
    "        test_dataset = lyrics_test\n",
    "    )\n",
    "\n",
    "    print(f'Training Improvement On Accuracy = +{(post_train_acc - pre_train_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Lyric Genre Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test lyrics\n",
    "pop_test = \"\"\"\"\n",
    "One. Don't pick up the phone. You know he's only calling cause he's drunk and alone.\n",
    "Two. Don't let him in. You'll have to kick him out again.\n",
    "Three. Don't be a friend. Cause you know you'll only wake up in his bed in the morning.\n",
    "Cause if you're under him. You're not getting over him.\n",
    "\"\"\"\n",
    "\n",
    "rock_test = \"\"\"\n",
    "We come from the land of the ice and snow\n",
    "From the midnight sun where the hot springs blow\n",
    "The hammer of the gods will drive our ships to new lands\n",
    "To fight the horde, singing and crying: Valhalla, I am coming!\n",
    "On we sweep with threshing oar\n",
    "Our only goal will be the western shore\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics:\n",
      "\n",
      "We come from the land of the ice and snow\n",
      "From the midnight sun where the hot springs blow\n",
      "The hammer of the gods will drive our ships to new lands\n",
      "To fight the horde, singing and crying: Valhalla, I am coming!\n",
      "On we sweep with threshing oar\n",
      "Our only goal will be the western shore\n",
      "\n",
      "\n",
      "Predicted Genre: rock (idx = 5)\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a custom song\n",
    "if EMBED_STRATEGY == 'DistilBERT':\n",
    "    genre_classification.distilerbert_clf_prediction(\n",
    "        lyrics = rock_test,\n",
    "        clf_model = transformer_model, # base_model, transformer_model\n",
    "        label_mapping = genre_map,\n",
    "        device = DEVICE\n",
    "    )\n",
    "elif EMBED_STRATEGY == 'GloVe':\n",
    "    genre_classification.glove_clf_prediction(\n",
    "        lyrics = rock_test, # pop_test, rock_test\n",
    "        clf_model = transformer_model,\n",
    "        glove_index = glove_index,\n",
    "        label_mapping = genre_map,\n",
    "        max_seq_len = MAX_GLOVE_LENGTH,\n",
    "        device = DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script End Time = 2025-03-27 14:27:01\n",
      "Duration = 34.17min\n"
     ]
    }
   ],
   "source": [
    "# wrap up\n",
    "END_TIME = datetime.now()\n",
    "SCRIPT_TIME = (END_TIME - START_TIME).seconds\n",
    "print(f'Script End Time = {END_TIME.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Duration = {SCRIPT_TIME / 60:.2f}min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6242-team157-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
