{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import gensim.downloader as api\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('song_lyrics.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean up current lyrics\n",
    "### remove chorus:, intro:, etc.\n",
    "### stop words, punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_brackets(text):\n",
    "  \"\"\"Removes all text between any matching pair of brackets, including the brackets themselves.\"\"\"\n",
    "  return re.sub(r'\\[.*?\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_lyrics(df):\n",
    "    sw = stopwords.words('english')\n",
    "\n",
    "    df['cleaned_lyrics'] = df['lyrics'].apply(remove_between_brackets)\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].str.lower()\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].apply(remove_stopwords)\n",
    "    df['tokenized_text'] = df[\"cleaned_lyrics\"].apply(word_tokenize)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleanse_lyrics(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean your sentences\n",
    "# stopwords = [YOUR_STOPWORDS_HERE]\n",
    "# cleaned_sentences = []\n",
    "# for sentence in sentences:\n",
    "#   cleaned = [word.lower() for word in sentence]\n",
    "#   cleaned = [word for word in cleaned if word not in stopwords]\n",
    "#   cleaned_sentences.append(cleaned)\n",
    "\n",
    "# build a word2vec model on your dataset\n",
    "sentences = df['tokenized_text'].tolist()\n",
    "# base_model = Word2Vec(vector_size=100, min_count=5)\n",
    "# base_model.build_vocab(sentences)\n",
    "# total_examples = base_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.train(sentences, total_examples=total_examples, epochs=base_model.epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(w for w in base_model.wv.index_to_key)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.wv.vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_word2vec(sentences):\n",
    "  \"\"\"\n",
    "  apply_word2vec\n",
    "  params: sentences -> 'tokenized_text'\n",
    "  returns: word2vec model\n",
    "  \n",
    "  Access vectors from base_model.wv.vectors and base_model.wv.index_to_key\n",
    "  \"\"\"\n",
    "  base_model = Word2Vec(vector_size=100, min_count=5)\n",
    "  base_model.build_vocab(sentences)\n",
    "  # base_model.train(sentences, total_examples=base_model.corpus_count, epochs=base_model.epochs) \n",
    "  return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apply_word2vec(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding: GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_glove(sentences, model=\"glove-wiki-gigaword-100\"):\n",
    "\n",
    "    print(\"Models available for use:\")\n",
    "    print(list(gensim.downloader.info()['models'].keys()))\n",
    "\n",
    "    glove_model = api.load(model)\n",
    "\n",
    "    ### initialize model\n",
    "    base_model = Word2Vec(vector_size=100, min_count=1)\n",
    "    base_model.build_vocab(sentences)\n",
    "    total_examples = base_model.corpus_count\n",
    "\n",
    "    base_model.build_vocab(glove_model.index_to_key, update=True)\n",
    "    base_model.train(sentences, total_examples=total_examples, epochs=base_model.epochs)\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_glove(sentences = sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### apply_glove and embedding matrix are not related to each. They are separate implementations depending on needed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_matrix(df):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df['cleaned_lyrics'])\n",
    "\n",
    "    max_length = max(len(data) for data in df['cleaned_lyrics'])\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)    \n",
    "\n",
    "    # padding text data\n",
    "    sequences = tokenizer.texts_to_sequences(df['cleaned_lyrics'])\n",
    "    padded_seq = pad_sequences(sequences, maxlen=12630, padding='post', truncating='post')\n",
    "\n",
    "    # create embedding index\n",
    "    embedding_index = {}\n",
    "    with open('glove.42B.300d.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_index[word] = coefs\n",
    "\n",
    "    # create embedding matrix\n",
    "    embedding_matrix = np.zeros((vocab_size+1, 300))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding: BERT and DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "# import numpy as np\n",
    "\n",
    "#load DistilBERT tokenizer and a pretrained model to avoid training from scratch\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and obtain embeddings\n",
    "def get_lyrics_embedding(lyrics):\n",
    "    tokens = tokenizer(\n",
    "        lyrics,\n",
    "        truncation = True,\n",
    "        padding = True, \n",
    "        max_length = 512, #DistilBERT has a max token limit of 512\n",
    "        return_tensors = \"pt\" #converting output as PyTorch since DistilBERT expects tensors not token IDs\n",
    "        )\n",
    "    \n",
    "    with torch.no_grad(): #removes gradient calculation to save memory usage since inferences are not needed as we are predicting, not training\n",
    "        output = model(**tokens)\n",
    "\n",
    "    cls_embedding = output.last_hidden_state[:, 0] #extract first token with CLS\n",
    "    cls_embedding = cls_embedding.detach() #detach from PyTorch's gradient computation \n",
    "    cls_embedding = cls_embedding.cpu() #converting tensor to CPU to ensure compatability (ie. NumPy array conversion)\n",
    "    cls_embedding = cls_embedding.squeeze() #remove any extra dimensions\n",
    "    \n",
    "    embedding = cls_embedding.numpy() #converting into NumPy array\n",
    "    return embedding\n",
    "\n",
    "#converting lyrics into embeddings using nrows\n",
    "embeddings = np.array([get_lyrics_embedding(lyric) for lyric in df['lyrics']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Are we using Keras / PyTorch?\n",
    "This may change the format and implementation of the current method of embedding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
