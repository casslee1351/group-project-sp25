{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nccru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nccru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "# from gensim.models import Word2Vec\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# import gensim.downloader as api\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/song_lyrics_clean.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean up current lyrics\n",
    "### remove chorus:, intro:, etc.\n",
    "### stop words, punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_brackets(text):\n",
    "  \"\"\"Removes all text between any matching pair of brackets, including the brackets themselves.\"\"\"\n",
    "  return re.sub(r'\\[.*?\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"Removes punctuation from a string.\"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_lyrics(df):\n",
    "\n",
    "    df['cleaned_lyrics'] = df['lyrics'].apply(remove_between_brackets)\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].apply(remove_punctuation)\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].str.lower()\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].str.replace(\",\", '')\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].apply(remove_stopwords)\n",
    "    df['tokenized_text'] = df[\"cleaned_lyrics\"].apply(word_tokenize)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she got a broke down el camino in the front ya...</td>\n",
       "      <td>country</td>\n",
       "      <td>got broke el camino yard blocks mom walks pink...</td>\n",
       "      <td>[got, broke, el, camino, yard, blocks, mom, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>later on when weve all come down and the stree...</td>\n",
       "      <td>country</td>\n",
       "      <td>later weve come streets funeral event falling ...</td>\n",
       "      <td>[later, weve, come, streets, funeral, event, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>longing for something more will i ever be free...</td>\n",
       "      <td>country</td>\n",
       "      <td>longing free free waitin sunshine door free oh...</td>\n",
       "      <td>[longing, free, free, waitin, sunshine, door, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my heart beats with the lonely rain wishin i c...</td>\n",
       "      <td>country</td>\n",
       "      <td>heart beats lonely rain wishin face change dia...</td>\n",
       "      <td>[heart, beats, lonely, rain, wishin, face, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an old cowpoke went ridin out one dark and win...</td>\n",
       "      <td>country</td>\n",
       "      <td>old cowpoke went ridin dark windy day rested s...</td>\n",
       "      <td>[old, cowpoke, went, ridin, dark, windy, day, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics    genre  \\\n",
       "0  she got a broke down el camino in the front ya...  country   \n",
       "1  later on when weve all come down and the stree...  country   \n",
       "2  longing for something more will i ever be free...  country   \n",
       "3  my heart beats with the lonely rain wishin i c...  country   \n",
       "4  an old cowpoke went ridin out one dark and win...  country   \n",
       "\n",
       "                                      cleaned_lyrics  \\\n",
       "0  got broke el camino yard blocks mom walks pink...   \n",
       "1  later weve come streets funeral event falling ...   \n",
       "2  longing free free waitin sunshine door free oh...   \n",
       "3  heart beats lonely rain wishin face change dia...   \n",
       "4  old cowpoke went ridin dark windy day rested s...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [got, broke, el, camino, yard, blocks, mom, wa...  \n",
       "1  [later, weve, come, streets, funeral, event, f...  \n",
       "2  [longing, free, free, waitin, sunshine, door, ...  \n",
       "3  [heart, beats, lonely, rain, wishin, face, cha...  \n",
       "4  [old, cowpoke, went, ridin, dark, windy, day, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanse_lyrics(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean your sentences\n",
    "# stopwords = [YOUR_STOPWORDS_HERE]\n",
    "# cleaned_sentences = []\n",
    "# for sentence in sentences:\n",
    "#   cleaned = [word.lower() for word in sentence]\n",
    "#   cleaned = [word for word in cleaned if word not in stopwords]\n",
    "#   cleaned_sentences.append(cleaned)\n",
    "\n",
    "# build a word2vec model on your dataset\n",
    "# sentences = df['tokenized_text'].tolist()\n",
    "# base_model = Word2Vec(vector_size=100, min_count=5)\n",
    "# base_model.build_vocab(sentences)\n",
    "# total_examples = base_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.train(sentences, total_examples=total_examples, epochs=base_model.epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(w for w in base_model.wv.index_to_key)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.wv.vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_word2vec(sentences):\n",
    "#   \"\"\"\n",
    "#   apply_word2vec\n",
    "#   params: sentences -> 'tokenized_text'\n",
    "#   returns: word2vec model\n",
    "  \n",
    "#   Access vectors from base_model.wv.vectors and base_model.wv.index_to_key\n",
    "#   \"\"\"\n",
    "#   base_model = Word2Vec(vector_size=100, min_count=5)\n",
    "#   base_model.build_vocab(sentences)\n",
    "#   # base_model.train(sentences, total_examples=base_model.corpus_count, epochs=base_model.epochs) \n",
    "#   return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = apply_word2vec(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding: GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def create_glove_matrix(df):\n",
    "    '''\n",
    "    Returns: df -> pandas dataframe with column of vectors for each word in the song\n",
    "    '''\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df['cleaned_lyrics'])\n",
    "\n",
    "    max_length = max(len(data) for data in df['cleaned_lyrics'])\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)    \n",
    "\n",
    "    # padding text data\n",
    "    sequences = tokenizer.texts_to_sequences(df['cleaned_lyrics'])\n",
    "    padded_seq = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "    # create embedding index\n",
    "    embedding_index = {}\n",
    "    with open('glove.42B.300d.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_index[word] = coefs\n",
    "\n",
    "    # # create embedding matrix\n",
    "    # embedding_matrix = np.zeros((vocab_size+1, 300))\n",
    "    # for word, i in word_index.items():\n",
    "    #     embedding_vector = embedding_index.get(word)\n",
    "    #     if embedding_vector is not None:\n",
    "    #         embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    word_vec_tensor = []\n",
    "    for index, row in df.iterrows():\n",
    "        word_vecs = []\n",
    "        for word in df['tokenized_text'][index]:\n",
    "            word_vec = embedding_index.get(word)\n",
    "            word_vecs.append(word_vec)\n",
    "\n",
    "        word_vec_tensor.append(word_vecs)\n",
    "\n",
    "    return word_vec_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she got a broke down el camino in the front ya...</td>\n",
       "      <td>country</td>\n",
       "      <td>got broke el camino yard blocks mom walks pink...</td>\n",
       "      <td>[got, broke, el, camino, yard, blocks, mom, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>later on when weve all come down and the stree...</td>\n",
       "      <td>country</td>\n",
       "      <td>later weve come streets funeral event falling ...</td>\n",
       "      <td>[later, weve, come, streets, funeral, event, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>longing for something more will i ever be free...</td>\n",
       "      <td>country</td>\n",
       "      <td>longing free free waitin sunshine door free oh...</td>\n",
       "      <td>[longing, free, free, waitin, sunshine, door, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my heart beats with the lonely rain wishin i c...</td>\n",
       "      <td>country</td>\n",
       "      <td>heart beats lonely rain wishin face change dia...</td>\n",
       "      <td>[heart, beats, lonely, rain, wishin, face, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an old cowpoke went ridin out one dark and win...</td>\n",
       "      <td>country</td>\n",
       "      <td>old cowpoke went ridin dark windy day rested s...</td>\n",
       "      <td>[old, cowpoke, went, ridin, dark, windy, day, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>no one will ever know my heart is breaking alt...</td>\n",
       "      <td>country</td>\n",
       "      <td>know heart breaking million teardrops start fl...</td>\n",
       "      <td>[know, heart, breaking, million, teardrops, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>i dont just love you i live you where im conce...</td>\n",
       "      <td>country</td>\n",
       "      <td>dont love live im concerned comes lifetimes id...</td>\n",
       "      <td>[dont, love, live, im, concerned, comes, lifet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>i got kicked off noahs ark i turn my cheek to ...</td>\n",
       "      <td>country</td>\n",
       "      <td>got kicked noahs ark turn cheek unkind remarks...</td>\n",
       "      <td>[got, kicked, noahs, ark, turn, cheek, unkind,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>if you miss the train im on you will know that...</td>\n",
       "      <td>country</td>\n",
       "      <td>miss train im know gone hear whistle blow mile...</td>\n",
       "      <td>[miss, train, im, know, gone, hear, whistle, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>a oneeyed jack named rio rode into monterey he...</td>\n",
       "      <td>country</td>\n",
       "      <td>oneeyed jack named rio rode monterey enemy wea...</td>\n",
       "      <td>[oneeyed, jack, named, rio, rode, monterey, en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                lyrics    genre  \\\n",
       "0    she got a broke down el camino in the front ya...  country   \n",
       "1    later on when weve all come down and the stree...  country   \n",
       "2    longing for something more will i ever be free...  country   \n",
       "3    my heart beats with the lonely rain wishin i c...  country   \n",
       "4    an old cowpoke went ridin out one dark and win...  country   \n",
       "..                                                 ...      ...   \n",
       "995  no one will ever know my heart is breaking alt...  country   \n",
       "996  i dont just love you i live you where im conce...  country   \n",
       "997  i got kicked off noahs ark i turn my cheek to ...  country   \n",
       "998  if you miss the train im on you will know that...  country   \n",
       "999  a oneeyed jack named rio rode into monterey he...  country   \n",
       "\n",
       "                                        cleaned_lyrics  \\\n",
       "0    got broke el camino yard blocks mom walks pink...   \n",
       "1    later weve come streets funeral event falling ...   \n",
       "2    longing free free waitin sunshine door free oh...   \n",
       "3    heart beats lonely rain wishin face change dia...   \n",
       "4    old cowpoke went ridin dark windy day rested s...   \n",
       "..                                                 ...   \n",
       "995  know heart breaking million teardrops start fl...   \n",
       "996  dont love live im concerned comes lifetimes id...   \n",
       "997  got kicked noahs ark turn cheek unkind remarks...   \n",
       "998  miss train im know gone hear whistle blow mile...   \n",
       "999  oneeyed jack named rio rode monterey enemy wea...   \n",
       "\n",
       "                                        tokenized_text  \n",
       "0    [got, broke, el, camino, yard, blocks, mom, wa...  \n",
       "1    [later, weve, come, streets, funeral, event, f...  \n",
       "2    [longing, free, free, waitin, sunshine, door, ...  \n",
       "3    [heart, beats, lonely, rain, wishin, face, cha...  \n",
       "4    [old, cowpoke, went, ridin, dark, windy, day, ...  \n",
       "..                                                 ...  \n",
       "995  [know, heart, breaking, million, teardrops, st...  \n",
       "996  [dont, love, live, im, concerned, comes, lifet...  \n",
       "997  [got, kicked, noahs, ark, turn, cheek, unkind,...  \n",
       "998  [miss, train, im, know, gone, hear, whistle, b...  \n",
       "999  [oneeyed, jack, named, rio, rode, monterey, en...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_glove_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vecs = []\n",
    "# for word in df['tokenized_text'][0]:\n",
    "#     word_vec = embedding_index.get(word)\n",
    "#     word_vecs.append(word_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding: BERT and DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "# import numpy as np\n",
    "\n",
    "#load DistilBERT tokenizer and a pretrained model to avoid training from scratch\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and obtain embeddings\n",
    "def get_lyrics_embedding(lyrics):\n",
    "    tokens = tokenizer(\n",
    "        lyrics,\n",
    "        truncation = True,\n",
    "        padding = True, \n",
    "        max_length = 512, #DistilBERT has a max token limit of 512\n",
    "        return_tensors = \"pt\" #converting output as PyTorch since DistilBERT expects tensors not token IDs\n",
    "        )\n",
    "    \n",
    "    with torch.no_grad(): #removes gradient calculation to save memory usage since inferences are not needed as we are predicting, not training\n",
    "        output = model(**tokens)\n",
    "\n",
    "    cls_embedding = output.last_hidden_state[:, 0] #extract first token with CLS\n",
    "    cls_embedding = cls_embedding.detach() #detach from PyTorch's gradient computation \n",
    "    cls_embedding = cls_embedding.cpu() #converting tensor to CPU to ensure compatability (ie. NumPy array conversion)\n",
    "    cls_embedding = cls_embedding.squeeze() #remove any extra dimensions\n",
    "    \n",
    "    embedding = cls_embedding.numpy() #converting into NumPy array\n",
    "    return embedding\n",
    "\n",
    "#converting lyrics into embeddings using nrows\n",
    "embeddings = np.array([get_lyrics_embedding(lyric) for lyric in df['lyrics']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Are we using Keras / PyTorch?\n",
    "This may change the format and implementation of the current method of embedding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
