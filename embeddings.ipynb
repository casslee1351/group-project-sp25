{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pokem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\pokem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "# from gensim.models import Word2Vec\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# import gensim.downloader as api\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('song_lyrics.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean up current lyrics\n",
    "### remove chorus:, intro:, etc.\n",
    "### stop words, punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_brackets(text):\n",
    "  \"\"\"Removes all text between any matching pair of brackets, including the brackets themselves.\"\"\"\n",
    "  return re.sub(r'\\[.*?\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"Removes punctuation from a string.\"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_lyrics(df):\n",
    "\n",
    "    df['cleaned_lyrics'] = df['lyrics'].apply(remove_between_brackets)\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].apply(remove_punctuation)\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].str.lower()\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].str.replace(\",\", '')\n",
    "    df['cleaned_lyrics'] = df['cleaned_lyrics'].apply(remove_stopwords)\n",
    "    df['tokenized_text'] = df[\"cleaned_lyrics\"].apply(word_tokenize)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>language_cld3</th>\n",
       "      <th>language_ft</th>\n",
       "      <th>language</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>killa cam killa cam cam killa cam killa cam ki...</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>yeah hah yeah rocafella invite somethin epic k...</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invite, somethin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>4743</td>\n",
       "      <td>{}</td>\n",
       "      <td>Maybe cause I'm eatin\\nAnd these bastards fien...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>maybe cause im eatin bastards fiend grub carry...</td>\n",
       "      <td>[maybe, cause, im, eatin, bastards, fiend, gru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>ugh killa baby kanye 1970s heron flow huh yeah...</td>\n",
       "      <td>[ugh, killa, baby, kanye, 1970s, heron, flow, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>ask young boy gon second time gon come tried t...</td>\n",
       "      <td>[ask, young, boy, gon, second, time, gon, come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   views  \\\n",
       "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1         Can I Live  rap      JAY-Z  1996  468624   \n",
       "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
       "3       Down and Out  rap    Cam'ron  2004  144404   \n",
       "4             Fly In  rap  Lil Wayne  2005   78271   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2                                            {}   \n",
       "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "4                                            {}   \n",
       "\n",
       "                                              lyrics  id language_cld3  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
       "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
       "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
       "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
       "\n",
       "  language_ft language                                     cleaned_lyrics  \\\n",
       "0          en       en  killa cam killa cam cam killa cam killa cam ki...   \n",
       "1          en       en  yeah hah yeah rocafella invite somethin epic k...   \n",
       "2          en       en  maybe cause im eatin bastards fiend grub carry...   \n",
       "3          en       en  ugh killa baby kanye 1970s heron flow huh yeah...   \n",
       "4          en       en  ask young boy gon second time gon come tried t...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [killa, cam, killa, cam, cam, killa, cam, kill...  \n",
       "1  [yeah, hah, yeah, rocafella, invite, somethin,...  \n",
       "2  [maybe, cause, im, eatin, bastards, fiend, gru...  \n",
       "3  [ugh, killa, baby, kanye, 1970s, heron, flow, ...  \n",
       "4  [ask, young, boy, gon, second, time, gon, come...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanse_lyrics(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean your sentences\n",
    "# stopwords = [YOUR_STOPWORDS_HERE]\n",
    "# cleaned_sentences = []\n",
    "# for sentence in sentences:\n",
    "#   cleaned = [word.lower() for word in sentence]\n",
    "#   cleaned = [word for word in cleaned if word not in stopwords]\n",
    "#   cleaned_sentences.append(cleaned)\n",
    "\n",
    "# build a word2vec model on your dataset\n",
    "# sentences = df['tokenized_text'].tolist()\n",
    "# base_model = Word2Vec(vector_size=100, min_count=5)\n",
    "# base_model.build_vocab(sentences)\n",
    "# total_examples = base_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.train(sentences, total_examples=total_examples, epochs=base_model.epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(w for w in base_model.wv.index_to_key)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.wv.vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_word2vec(sentences):\n",
    "#   \"\"\"\n",
    "#   apply_word2vec\n",
    "#   params: sentences -> 'tokenized_text'\n",
    "#   returns: word2vec model\n",
    "  \n",
    "#   Access vectors from base_model.wv.vectors and base_model.wv.index_to_key\n",
    "#   \"\"\"\n",
    "#   base_model = Word2Vec(vector_size=100, min_count=5)\n",
    "#   base_model.build_vocab(sentences)\n",
    "#   # base_model.train(sentences, total_examples=base_model.corpus_count, epochs=base_model.epochs) \n",
    "#   return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = apply_word2vec(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding: GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_matrix(df):\n",
    "    '''\n",
    "    Returns: df -> pandas dataframe with column of vectors for each word in the song\n",
    "    '''\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df['cleaned_lyrics'])\n",
    "\n",
    "    max_length = max(len(data) for data in df['cleaned_lyrics'])\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)    \n",
    "\n",
    "    # padding text data\n",
    "    sequences = tokenizer.texts_to_sequences(df['cleaned_lyrics'])\n",
    "    padded_seq = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "    # create embedding index\n",
    "    embedding_index = {}\n",
    "    with open('glove.42B.300d.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_index[word] = coefs\n",
    "\n",
    "    # # create embedding matrix\n",
    "    # embedding_matrix = np.zeros((vocab_size+1, 300))\n",
    "    # for word, i in word_index.items():\n",
    "    #     embedding_vector = embedding_index.get(word)\n",
    "    #     if embedding_vector is not None:\n",
    "    #         embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    word_vec_tensor = []\n",
    "    for index, row in df.iterrows():\n",
    "        word_vecs = []\n",
    "        for word in df['tokenized_text'][index]:\n",
    "            word_vec = embedding_index.get(word)\n",
    "            word_vecs.append(word_vec)\n",
    "\n",
    "    word_vec_tensor.append(word_vecs)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_glove_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vecs = []\n",
    "# for word in df['tokenized_text'][0]:\n",
    "#     word_vec = embedding_index.get(word)\n",
    "#     word_vecs.append(word_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding: BERT and DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "# import numpy as np\n",
    "\n",
    "#load DistilBERT tokenizer and a pretrained model to avoid training from scratch\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and obtain embeddings\n",
    "def get_lyrics_embedding(lyrics):\n",
    "    tokens = tokenizer(\n",
    "        lyrics,\n",
    "        truncation = True,\n",
    "        padding = True, \n",
    "        max_length = 512, #DistilBERT has a max token limit of 512\n",
    "        return_tensors = \"pt\" #converting output as PyTorch since DistilBERT expects tensors not token IDs\n",
    "        )\n",
    "    \n",
    "    with torch.no_grad(): #removes gradient calculation to save memory usage since inferences are not needed as we are predicting, not training\n",
    "        output = model(**tokens)\n",
    "\n",
    "    cls_embedding = output.last_hidden_state[:, 0] #extract first token with CLS\n",
    "    cls_embedding = cls_embedding.detach() #detach from PyTorch's gradient computation \n",
    "    cls_embedding = cls_embedding.cpu() #converting tensor to CPU to ensure compatability (ie. NumPy array conversion)\n",
    "    cls_embedding = cls_embedding.squeeze() #remove any extra dimensions\n",
    "    \n",
    "    embedding = cls_embedding.numpy() #converting into NumPy array\n",
    "    return embedding\n",
    "\n",
    "#converting lyrics into embeddings using nrows\n",
    "embeddings = np.array([get_lyrics_embedding(lyric) for lyric in df['lyrics']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Are we using Keras / PyTorch?\n",
    "This may change the format and implementation of the current method of embedding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
